# Z-Image-Turbo Environment Configuration
# Copy this file to .env and configure your settings

# ============================================
# LLM Provider Selection
# ============================================
# Choose your LLM provider: ollama, openai, grok
# Default: ollama
LLM_PROVIDER=ollama

# ============================================
# Ollama Configuration (default provider)
# ============================================
# Local Ollama server URL
OLLAMA_URL=http://localhost:11434/v1
# Ollama model name
OLLAMA_MODEL=gemma3:27b

# ============================================
# OpenAI Configuration
# ============================================
# Set LLM_PROVIDER=openai to use OpenAI
# Your OpenAI API key (required for OpenAI provider)
OPENAI_API_KEY=
# OpenAI model name
OPENAI_MODEL=gpt-4o-mini
# OpenAI API base URL (optional, for custom endpoints)
OPENAI_BASE_URL=https://api.openai.com/v1

# ============================================
# Grok (xAI) Configuration
# ============================================
# Set LLM_PROVIDER=grok to use Grok
# Your xAI API key (required for Grok provider)
# Get your API key at: https://console.x.ai
GROK_API_KEY=
# Grok model name
GROK_MODEL=grok-3-mini
# xAI API base URL
GROK_BASE_URL=https://api.x.ai/v1

# ============================================
# HuggingFace Configuration (for model downloads)
# ============================================
# Optional: Use mirror for faster downloads in China
# HF_ENDPOINT=https://hf-mirror.com
